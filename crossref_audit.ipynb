{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests \n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pull the existing titles on Direct and check which have been deposited with Crossref ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ZiplineLive_titleid_eisbn_doi_sclanding_20191108 2.csv', delimiter='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['Title_ID', 'ISBN', 'DOI', 'URL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    print(\"{}/{}\".format(index, len(df)))\n",
    "    try:\n",
    "        URL = \"https://api.crossref.org/works?filter=doi:{}\".format(row.DOI)\n",
    "        print(URL)\n",
    "        r = requests.get(url = URL) \n",
    "        data = r.json() \n",
    "        response = data['message']['total-results']\n",
    "        df.loc[index, 'Deposited'] = response\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = df.groupby('Deposited')\n",
    "g['Deposited'].value_counts()\n",
    "\n",
    "not_deposited = df[df['Deposited']==0.0]\n",
    "not_deposited.to_csv('not_deposited.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_deposited.tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generate Crossref XML ###\n",
    "\n",
    "# Values needed for deposit:\n",
    "    # IDTitle\n",
    "    # auth_1\n",
    "    # auth_type_1\n",
    "    # auth_2\n",
    "    # auth_type_2\n",
    "    # auth_3\n",
    "    # auth_type_3\n",
    "    # auth_4\n",
    "    # auth_type_4\n",
    "    # auth_5\n",
    "    # auth_type_5\n",
    "    # Title\n",
    "    # Subtitle\n",
    "    # ISBN\n",
    "    # Pub_Date\n",
    "    # DOI\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import_file = \"allbooks_export.csv\"\n",
    "import_df = pd.read_csv(import_file, encoding='latin-1', header=None)\n",
    "import_df.columns = ['Title', 'auth_1', 'auth_type_1', 'auth_2', \n",
    "                     'auth_type_2', 'auth_3', 'auth_type_3', \n",
    "                     'auth_4', 'auth_type_4', 'auth_5', 'auth_type_5', \n",
    "                     'Subtitle', 'Title_ID', 'ISBN', 'Pub_Date', 'DOI']\n",
    "import_df = import_df.drop(columns=['DOI', 'ISBN'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = pd.merge(import_df, not_deposited, on='Title_ID')\n",
    "df_merge['Pub_Date']= pd.to_datetime(df_merge['Pub_Date'], format='%m/%d/%Y') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column with just the month taken from LISTDATE\n",
    "def get_year(row):\n",
    "    return row['Pub_Date'].year\n",
    "\n",
    "df_merge['Year'] = df_merge.apply(get_year, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {'AU': 'author', 'ED': 'editor', 'TR': 'translator'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datetime object containing current date and time\n",
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%d%m%Y%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_header = \"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "<doi_batch xmlns=\"http://www.crossref.org/schema/4.3.7\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" version=\"4.3.7\" xsi:schemaLocation=\"http://www.crossref.org/schema/4.3.7 http://www.crossref.org/schemas/crossref4.3.7.xsd\">\n",
    "    <head>\n",
    "        <doi_batch_id>{}</doi_batch_id>\n",
    "        <timestamp>{}</timestamp>\n",
    "        <depositor>\n",
    "            <depositor_name>The MIT Press</depositor_name>\n",
    "            <email_address>kmcdouga@mit.edu</email_address>\n",
    "        </depositor>\n",
    "        <registrant>The MIT Press</registrant>\n",
    "    </head>\n",
    "    <body>\"\"\".format(\"Batch_\"+dt_string, dt_string)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createXML(row):\n",
    "\n",
    "    master_xml = []\n",
    "#     for index, row in import_df.iterrows():\n",
    "    xml = ['<book book_type=\"monograph\"><book_metadata language=\"en\">']\n",
    "    if row['auth_type_1'] == 'AU' or row['auth_type_1'] == 'ED' or row['auth_type_1'] == 'TR':\n",
    "        xml.append('<contributors>')\n",
    "        names = row['auth_1'].split(\",\")\n",
    "        try:\n",
    "            fname = names[1]\n",
    "            lname = names[0]\n",
    "            xml.append(\"\"\"<person_name sequence=\"first\" contributor_role=\"{}\">\n",
    "                           <given_name>{}</given_name>\n",
    "                           <surname>{}</surname>\n",
    "                           </person_name>\"\"\".format(dict[row['auth_type_1']], names[1].strip(), names[0].strip()))\n",
    "        except IndexError:\n",
    "            xml.append(\"\"\"<organization sequence=\"first\" contributor_role=\"author\">{}</organization>\"\"\".format(row['auth_type_1']))\n",
    "\n",
    "    if row['auth_type_2'] == 'AU' or row['auth_type_2'] == 'ED' or row['auth_type_2'] == 'TR':\n",
    "        names = row['auth_2'].split(\",\")\n",
    "        try:\n",
    "            fname = names[1]\n",
    "            lname = names[0]\n",
    "            xml.append(\"\"\"<person_name sequence=\"first\" contributor_role=\"{}\">\n",
    "                           <given_name>{}</given_name>\n",
    "                           <surname>{}</surname>\n",
    "                           </person_name>\"\"\".format(dict[row['auth_type_2']], names[1].strip(), names[0].strip()))\n",
    "        except IndexError:\n",
    "            xml.append(\"\"\"<organization sequence=\"first\" contributor_role=\"author\">{}</organization>\"\"\".format(row['auth_type_2']))\n",
    "\n",
    "    if row['auth_type_3'] == 'AU' or row['auth_type_3'] == 'ED' or row['auth_type_3'] == 'TR':\n",
    "        names = row['auth_3'].split(\",\")\n",
    "        try:\n",
    "            fname = names[1]\n",
    "            lname = names[0]\n",
    "            xml.append(\"\"\"<person_name sequence=\"first\" contributor_role=\"{}\">\n",
    "                           <given_name>{}</given_name>\n",
    "                           <surname>{}</surname>\n",
    "                           </person_name>\"\"\".format(dict[row['auth_type_3']], names[1].strip(), names[0].strip()))\n",
    "        except IndexError:\n",
    "            xml.append(\"\"\"<organization sequence=\"first\" contributor_role=\"author\">{}</organization>\"\"\".format(row['auth_type_3']))\n",
    "\n",
    "    if row['auth_type_4'] == 'AU' or row['auth_type_4'] == 'ED' or row['auth_type_4'] == 'TR':\n",
    "        names = row['auth_4'].split(\",\")\n",
    "        try:\n",
    "            fname = names[1]\n",
    "            lname = names[0]\n",
    "            xml.append(\"\"\"<person_name sequence=\"first\" contributor_role=\"{}\">\n",
    "                           <given_name>{}</given_name>\n",
    "                           <surname>{}</surname>\n",
    "                           </person_name>\"\"\".format(dict[row['auth_type_4']], names[1].strip(), names[0].strip()))\n",
    "        except IndexError:\n",
    "            xml.append(\"\"\"<organization sequence=\"first\" contributor_role=\"author\">{}</organization>\"\"\".format(row['auth_type_4']))\n",
    "\n",
    "\n",
    "    if row['auth_type_5'] == 'AU' or row['auth_type_5'] == 'ED' or row['auth_type_5'] == 'TR':\n",
    "        names = row['auth_5'].split(\",\")\n",
    "        try:\n",
    "            fname = names[1]\n",
    "            lname = names[0]\n",
    "            xml.append(\"\"\"<person_name sequence=\"first\" contributor_role=\"{}\">\n",
    "                           <given_name>{}</given_name>\n",
    "                           <surname>{}</surname>\n",
    "                           </person_name>\"\"\".format(dict[row['auth_type_5']], names[1].strip(), names[0].strip()))\n",
    "        except IndexError:\n",
    "            xml.append(\"\"\"<organization sequence=\"first\" contributor_role=\"author\">{}</organization>\"\"\".format(row['auth_type_5']))\n",
    "\n",
    "    xml.append('</contributors>')\n",
    "\n",
    "    if type(row[\"Subtitle\"]) == str:\n",
    "        xml.append('<titles><title>{0}</title><subtitle>{1}</subtitle></titles>'.format(row[\"Title\"], row[\"Subtitle\"]))\n",
    "    if type(row[\"Subtitle\"]) == float:\n",
    "        xml.append('<titles><title>{0}</title></titles>'.format(row[\"Title\"]))\n",
    "    if type(row[\"Subtitle\"]) != float and type(row[\"Subtitle\"]) != str:\n",
    "        print(\"unrecognized type in \\\"subtitle\\\" field\")\n",
    "\n",
    "\n",
    "    xml.append('<publication_date><year>{0}</year></publication_date>'.format(row[\"Year\"]))\n",
    "    xml.append('<isbn>{0}</isbn>'.format(row[\"ISBN\"]))\n",
    "    xml.append('<publisher><publisher_name>The MIT Press</publisher_name></publisher>')\n",
    "    xml.append('<doi_data><doi>{}</doi><resource>{}</resource></doi_data>'.format(row[\"DOI\"], row[\"URL\"]))\n",
    "    xml.append('</book_metadata></book>')\n",
    "    master_xml.append(xml)\n",
    "    return '\\n'.join(xml)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('out.xml', 'w') as f:\n",
    "    print(xml_header, file = f)\n",
    "    print('\\n'.join(df_merge.apply(createXML, axis=1)), file=f)  # Python 3.x\n",
    "    print('</body></doi_batch>', file = f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
